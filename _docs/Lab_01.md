# Лабораторная работа №1. Реализация метода обратного распространения ошибки

## Постановка задачи

В рамках первой лабораторной работы необходимо выполнить реализацию
и тестирование метода обратного распространения ошибки для классификации
рукописных цифр из набора данных [MNIST](https://yann.lecun.com/exdb/mnist)
без использования фреймворков глубокого обучения.

Конфигурация нейронной сети:
- Входной слой содержит w x h нейронов, что соответствует разрешению
  одноканального изображения (для изображений в базе MNIST составляет 28x28).
- Выходной слой содержит k нейронов, что соответствует количеству классов
  изображений (для задачи классификации рукописных цифр MNIST – 10 классов).
- Скрытый слой содержит s нейронов (параметр).
- Функция активации на скрытом слое - функция ReLU.
- Функции активации на выходном слое - функция softmax.

Скорость обучения (learning rate), размер пачки данных (batch size), количество
эпох являются параметрами метода обучения.

В качестве функции ошибки используется кросс-энтропия.
**Примечание:** функция активации softmax вместе с функцией ошибки
кросс-энтропия упрощают вывод формул.

Последовательность действий, которую должен реализовывать скрипт: 
1. Загрузка и проверка данных. Необходимо обеспечить демонстрацию избранных
   изображений и меток классов для подтверждения корректности загрузки
   и совпадения размерностей.
1. Реализация метода обратного распространения ошибки. По окончании каждой эпохи
   в процессе обучения модели необходимо выводить ошибку классификации
   на тренировочном наборе данных и время выполнения эпохи.
1. Использование разработанного метода обратного ошибки для обучения модели
   с целью решения задачи классификации рукописных цифр.
1. Валидация обученной модели на тестовой выборке. Для обученной модели
   необходимо вычислить и вывести ошибку классификации на тестовом наборе
   данных.

Набор тестовых параметров для демонстрации корректности процедуры обучения
нейронной сети:
- Размер пачки может меняться от 8 до 64 изображений (в зависимости
  от доступного объема памяти).
- Скорость обучения - 0.1.
- Количество скрытых нейронов s - 300.
- Количество эпох – 20.

## Последовательность публикации результатов выполнения работы на GitHub

1. Создать копию репозитория курса (кнопка Fork в правом верхнем углу).
1. Создать ветку для первой лабораторной работы в собственной копии репозитория.
1. Подготовленный бланк Jupiter notebook и его копия в формате html или pdf
   необходимо загрузить в директорию с названием `<FamiliaIO>`, где  `<FamiliaIO>` -
   фамилия и инициалы слушателя курса. Бланк должен содержать отчет по каждому
   этапу реализации. Загружаемые файлы должны иметь название `Lab_01`.
1. Сделать пулл-реквест в репозиторий курса.

## Система оценивания

Максимальное количество баллов - 30 баллов:
- 5 баллов за подтверждение загрузки и проверки корректности данных.
- 10 баллов за реализацию и подтверждение корректности метода обратного
  распространения ошибки.
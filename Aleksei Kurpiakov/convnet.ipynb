{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4cbd32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d5148801",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a38efd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, pin_memory=True, num_workers=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, pin_memory=True, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd974262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_blk(inputChanneles, outputChannels, pooling):\n",
    "    layers = [nn.Conv2d(inputChanneles, outputChannels, kernel_size=3, padding=1), nn.BatchNorm2d(outputChannels), nn.ReLU()]\n",
    "\n",
    "    if pooling:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df48b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, inputChannels, outputChannels):\n",
    "        super(Network, self).__init__()\n",
    "        self._block = nn.Sequential(\n",
    "            conv_blk(inputChannels, 64, False),\n",
    "            conv_blk(64, 64, False),\n",
    "            conv_blk(64, 128, True),\n",
    "            conv_blk(128, 128, False),\n",
    "            conv_blk(128, 256, True),\n",
    "            conv_blk(256, 256, False),\n",
    "            conv_blk(256, 512, True),\n",
    "            conv_blk(512, 512, False)\n",
    "        )\n",
    "\n",
    "        self._adaptive_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self._res = nn.Linear(512, outputChannels)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self._block(X)\n",
    "        out = self._adaptive_pool(out)\n",
    "        out =  torch.flatten(out, 1)\n",
    "        out = self._res(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1965c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_once(model, train_loader, criterion, optimizer, device):\n",
    "    avg_accuracy = []\n",
    "    avg_loss = []\n",
    "\n",
    "    for data in train_loader:\n",
    "        image = data[0].to(device)    \n",
    "        label = data[1].to(device)    \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mod = model(image)\n",
    "\n",
    "        loss = criterion(mod, label)\n",
    "        avg_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_accuracy.append((torch.argmax(mod, dim=1) == label).float().mean())\n",
    "\n",
    "    return torch.tensor(avg_loss).mean().cpu().detach().numpy(), torch.tensor(avg_accuracy).mean().cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10239707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __main__():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    model = Network(3, 10).to(device)\n",
    "\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    epochs = 20\n",
    "    print(\"Start:\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        epoch_loss, train_acc = train_once(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{epochs} | loss={epoch_loss:.4f} | \"f\"train_acc≈{train_acc:.4f}\")\n",
    "\n",
    "        loss_list.append(epoch_loss)\n",
    "        acc_list.append(train_acc)\n",
    "\n",
    "\n",
    "    loss, accuracy, cur_total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            u = model(images)\n",
    "\n",
    "            loss += criterion(u, labels).item()\n",
    "            cur_total += labels.size(0)\n",
    "\n",
    "            _, predicted_labels = torch.max(u.data, 1)\n",
    "\n",
    "            accuracy += (predicted_labels == labels).sum().item()\n",
    "        \n",
    "    print(f\"Loss: {loss / cur_total:.4f}, Test Accuracy: {accuracy / cur_total:.4f}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e499afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  __main__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68fd9d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "cuda\n",
    "Start:\n",
    "Epoch 01/20 | loss=1.5886 | train_acc≈0.4148\n",
    "Epoch 02/20 | loss=0.9589 | train_acc≈0.6596\n",
    "Epoch 03/20 | loss=0.6716 | train_acc≈0.7649\n",
    "Epoch 04/20 | loss=0.5140 | train_acc≈0.8219\n",
    "Epoch 05/20 | loss=0.3991 | train_acc≈0.8622\n",
    "Epoch 06/20 | loss=0.3032 | train_acc≈0.8955\n",
    "Epoch 07/20 | loss=0.2324 | train_acc≈0.9184\n",
    "Epoch 08/20 | loss=0.1641 | train_acc≈0.9414\n",
    "Epoch 09/20 | loss=0.1225 | train_acc≈0.9569\n",
    "Epoch 10/20 | loss=0.0939 | train_acc≈0.9668\n",
    "Epoch 11/20 | loss=0.0783 | train_acc≈0.9724\n",
    "Epoch 12/20 | loss=0.0684 | train_acc≈0.9758\n",
    "Epoch 13/20 | loss=0.0634 | train_acc≈0.9782\n",
    "Epoch 14/20 | loss=0.0542 | train_acc≈0.9817\n",
    "Epoch 15/20 | loss=0.0503 | train_acc≈0.9829\n",
    "Epoch 16/20 | loss=0.0461 | train_acc≈0.9842\n",
    "Epoch 17/20 | loss=0.0484 | train_acc≈0.9845\n",
    "Epoch 18/20 | loss=0.0367 | train_acc≈0.9875\n",
    "Epoch 19/20 | loss=0.0410 | train_acc≈0.9862\n",
    "Epoch 20/20 | loss=0.0368 | train_acc≈0.9876\n",
    "Loss: 0.0113, Test Accuracy: 0.8585\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
